---
title: "126 Data Project, Summary"
date: "Sam Ream, Valeria Lopez, Skyler Yee"
output:
  pdf_document:
    latex_engine: xelatex
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
# knit options
knitr::opts_chunk$set(echo = F,
                      results = 'markup',
                      fig.width = 4,
                      fig.height = 3,
                      fig.align = 'center',
                      message = F,
                      warning = F)

# packages
library(tidyverse)
library(faraway)
library(RSQLite)
library(skimr)
library(GGally)
library(tidymodels)
library(leaps)
library(glmnet)
library(gridExtra)
library(corrr)
library(ggcorrplot)
library(FactoMineR)
library(factoextra)
```

```{r, echo=FALSE}
ball <- dbConnect(drv=RSQLite::SQLite(), dbname="../../data/database.sqlite")
```

```{r, echo =FALSE}
batting <- dbGetQuery(ball, "
                            SELECT
                            sum(ab) AS AT_BAT,
                            player_id,
                            sum(r) AS RUNS,
                            sum(hr) AS HOME_RUNS, 
                            sum(triple) AS TRIPLE,
                            sum(double) AS DOUBLE,
                            (sum(h) -  sum(hr) - sum(triple) - sum(double)) AS SINGLES,
                            sum(bb) AS WALKS,
                            sum(ibb) AS INT_WALKS,
                            sum(sb) AS STOLEN_BASES,
                            sum(hbp) AS HIT_BY_PITCH
                            
                            FROM
                            batting
                            where
                            year > 2000
                            group by
                            player_id
                            
                   ")
sumbat <- batting
batting <- subset(batting,batting[,1]>100)


for (x in 3:11) 
{
  batting[,x] <- batting[,x] / 1
}

set.seed(5)
batting <- sample_n(batting, 500, replace = FALSE)

players <- dbGetQuery(ball, "
                      
                      SELECT 
                      player_id,
                      (weight / POWER(height, 2)) *703 AS BMI,
                      bats as HAND
                      FROM
                      player
                      
                      ")




players <- subset(players, players[,2]>0)



for ( x in 1:17918)
{
  if(players[x,2] <= 18.5) {players[x,2] <- "U"} 
  else if(players[x,2] <= 24.9) {players[x,2] <- "H"}
  else if(players[x,2] <= 29.9) {players[x,2] <- "O"}
  else {players[x,2] <- "B"}
}

batting <-  merge(batting, players, by="player_id" )
```

# Step 1


# Step 2-3

```{r}
library(lmtest)
DOUBLE <- batting$DOUBLE
g <- lm(batting$RUNS~DOUBLE ,data=batting)
dwtest(batting$RUNS ~ batting$DOUBLE, data=batting)
```


```{r fig.cap= "Scatter plot of the relationship between Runs and Doubles"}
par(mfrow = c(1, 2))
plot(batting$DOUBLE, batting$RUNS, ylab = "Runs", xlab = "Doubles")
abline(0,2.4, col="red",)
abline(-150,2.4, col="blue",)
abline(200,2.4, col="blue",)
```

```{r fig.cap= "QQ-Plot showing that the data is not normally distributed"}
qqnorm(batting$RUNS)
qqline(batting$RUNS)
```

**- Linearity:** All the points on the relationship plot above are arranged in a very linear way without transformations

**- Constant Variance:** Almost all of the points have a similar distance from a proposed straight line.

**- Independence:** With the knowledge that one batter hitting the ball well enough to get a double does not affect the likelihood of the next batter doing the same, we know that the predictors are independent of one another.

**- Normality:** While our errors do not appear to be normally distributed, our large sample size allows us to leverage the Central Limit Theorem to make meaningful analysis.

```{r include=FALSE}
slm <- summary(g)
anova_lm <- anova(g)
```

# Hypothesis Testing

## Significance Test

$$H_0: \beta_i=0$$

$$H_a: \beta_1 \neq 0$$

$$\alpha = 0.05$$

```{r include=FALSE}
test_stat <- slm$coefficients[,3][2]
test_stat #102.942 # from slm
p_value <- slm$coefficients[,4][2]
p_value
```

$\textbf{Test Statistic =}\ 102.942$

$\textbf{P Value} \approx 0$

We reject $H_0$ at 0.05 level. Thus, the amount of doubles a player hits is a significant predictor of how many runs the player scores.

# Fit of Model

The $R^2$ value of our model is 0.9551, which means that the model explains 95.51% of the variance of the recorded events. Additionally, the residual plot in figure 3 shows how the data points share a similar spread which implies that the model is a good fit.

```{r include=FALSE}
summary(lm(batting$DOUBLE ~ batting$RUNS))
```

```{r fig.cap= "Residual Plot of the fitted model"}
model <- lm(batting$RUNS ~ batting$DOUBLE)

res <- resid(model)

plot(fitted(model), res, ylab = "Residuals", xlab = "Fitted Model")
```

# Computational Models

For our computational models, we used the predictors: Total Intentional Walks, Singles, Triples, Stolen Bases, and Home Runs obtained in a career. We selected these predictors because of their low correlation in addition to their interesting relation to obtained Runs.

### Model 1 - Full Model ( $\Omega$ )

$\mathbb{E}[Y]=\text{Intercept } + \text{Intentional Walks }+\text{Singles }+\text{Triples }+\text{Stolen Bases }+\text{Home Runs}+\epsilon$

### Model 2 - Reduced Model ( $\omega$ )

$\mathbb{E}[Y]=\text{Intercept } + \text{Singles }+\text{Triples }+\text{Home Runs}+\epsilon$

### Comparison:

$H_0: \beta \in \omega :\text{The Reduced Model is sufficient}$

$H_\alpha: \beta \in \Omega \text{\\} \omega \in w :\text{The Reduced Model is not sufficient}$

```{r}
model_1 <- lm(RUNS~INT_WALKS + SINGLES + TRIPLE + STOLEN_BASES + HOME_RUNS, data = batting)
model_2 <- lm(RUNS~SINGLES + TRIPLE + HOME_RUNS, data = batting)
anova(model_1, model_2)
```

### Conclusion

As we rejected \$H_0\$ in favor for \$H\_\\alpha\$, we can determine that the reduced model does not model the data well enough to justify the reduction in predictors. As such, we decided to use model 1, the full model, as our computational model.

# Statistical Model

We used a stepwise search to create the best model for our data. For a size of 4 predictors the variables home runs, singles, walks, and stolen bases create a well fit model.

# Final Model Selection

Between the two models we created, the statistical model and computational model, we selected the statistical model. The reason behind this selection is that the statistical model has a larger $R_{adj}^2$ value and we want to explain as much of the variance as possible in our model.


# Step 4

```{r}
tempco <- round(cor(batting[,c('TRIPLE', 'HOME_RUNS', 'SINGLES', 'WALKS', 'DOUBLE', 'INT_WALKS', 'STOLEN_BASES', 'HIT_BY_PITCH')]), 2)
ik <- 1
```

### Collinearity table

|                    |                T |               HR |                S |                W |                D |               IW |               SB |                             HBP |
|:-------|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|
| TRIPLE (T)        | `r tempco[ik,1]` | `r tempco[ik,2]` | `r tempco[ik,3]` | `r tempco[ik,4]` | `r tempco[ik,5]` | `r tempco[ik,6]` | `r tempco[ik,7]` | `r tempco[ik,8]` `r ik <- ik+1` |
| HOME_RUNS (HR)     | `r tempco[ik,1]` | `r tempco[ik,2]` | `r tempco[ik,3]` | `r tempco[ik,4]` | `r tempco[ik,5]` | `r tempco[ik,6]` | `r tempco[ik,7]` | `r tempco[ik,8]` `r ik <- ik+1` |
| SINGLES (S)        | `r tempco[ik,1]` | `r tempco[ik,2]` | `r tempco[ik,3]` | `r tempco[ik,4]` | `r tempco[ik,5]` | `r tempco[ik,6]` | `r tempco[ik,7]` | `r tempco[ik,8]` `r ik <- ik+1` |
| WALKS (W)          | `r tempco[ik,1]` | `r tempco[ik,2]` | `r tempco[ik,3]` | `r tempco[ik,4]` | `r tempco[ik,5]` | `r tempco[ik,6]` | `r tempco[ik,7]` | `r tempco[ik,8]` `r ik <- ik+1` |
| DOUBLE (D)         | `r tempco[ik,1]` | `r tempco[ik,2]` | `r tempco[ik,3]` | `r tempco[ik,4]` | `r tempco[ik,5]` | `r tempco[ik,6]` | `r tempco[ik,7]` | `r tempco[ik,8]` `r ik <- ik+1` |
| INT_WALKS (IW)     | `r tempco[ik,1]` | `r tempco[ik,2]` | `r tempco[ik,3]` | `r tempco[ik,4]` | `r tempco[ik,5]` | `r tempco[ik,6]` | `r tempco[ik,7]` | `r tempco[ik,8]` `r ik <- ik+1` |
| STOLEN_BASES (SB)  | `r tempco[ik,1]` | `r tempco[ik,2]` | `r tempco[ik,3]` | `r tempco[ik,4]` | `r tempco[ik,5]` | `r tempco[ik,6]` | `r tempco[ik,7]` | `r tempco[ik,8]` `r ik <- ik+1` |
| HIT_BY_PITCH (HBP) | `r tempco[ik,1]` | `r tempco[ik,2]` | `r tempco[ik,3]` | `r tempco[ik,4]` | `r tempco[ik,5]` | `r tempco[ik,6]` | `r tempco[ik,7]` | `r tempco[ik,8]` `r ik <- ik+1` |

As we observed the collinearity between certain predictors to be high as seen in the table above, we implemented a Ridge and Lasso regression on the entire set of predictors to make a model that fits well and utilizes all predictors. While the Lasso regression did not eliminate any predictors, it did result in the best fit of all the previous models as can be demonstrated in the plot and table below.

```{r, echo =FALSE}


y <- batting$RUNS
x <- data.matrix(batting[, c('TRIPLE', 'HOME_RUNS', 'SINGLES', 'WALKS', 'DOUBLE', 'INT_WALKS', 'STOLEN_BASES', 'HIT_BY_PITCH')])

stat_model <- lm(RUNS~HOME_RUNS + SINGLES + WALKS + STOLEN_BASES, data = batting)
slm <- lm(RUNS~DOUBLE, data = batting)

cv_model <- cv.glmnet(x, y, alpha = 1)
model <- glmnet(x, y, alpha = 1)

cv_model_ridge <- cv.glmnet(x, y, alpha = 0)
ridge_model <- glmnet(x, y, alpha = 0)
model <- glmnet(x, y, alpha = 1)


best_lambda_r <- cv_model_ridge$lambda.min
best_lambda <- cv_model$lambda.min






```




Coefficients of the Ridge Model
```{r}
temp_ridge <- cv.glmnet(x, y, alpha = 0)
coef(temp_ridge)
```

In observing our coefficients, we can see that Triples have the largest effect (an increase of 1.9420 expected runs per Triple) on the expected number of Runs and that every predictor contributes some information to the model.

Coefficients of the Lasso Model
```{r}
temp_lasso <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(temp_lasso)
```

Through observing our coefficients, we can observe that Triples and Home Runs have a much larger effect on the expected number of Runs than any other predictor in a lasso regression model. Intentional walks also decreases the expected number of runs and no predictor can be removed without consequence.


```{r}
batting <- dbGetQuery(ball, "
                            SELECT
                            sum(ab) AS AT_BAT,
                            player_id,
                            sum(r) AS RUNS,
                            sum(hr) AS HOME_RUNS, 
                            sum(triple) AS TRIPLE,
                            sum(double) AS DOUBLE,
                            (sum(h) -  sum(hr) - sum(triple) - sum(double)) AS SINGLES,
                            sum(bb) AS WALKS,
                            sum(ibb) AS INT_WALKS,
                            sum(sb) AS STOLEN_BASES,
                            sum(hbp) AS HIT_BY_PITCH
                            
                            FROM
                            batting
                            where
                            year > 2000
                            group by
                            player_id
                            
                   ")
sumbat <- batting
batting <- subset(batting,batting[,1]>100)

set.seed(4)
batting <- sample_n(batting, 500, replace = FALSE)

players <- dbGetQuery(ball, "
                      
                      SELECT 
                      player_id,
                      (weight / POWER(height, 2)) *703 AS BMI,
                      bats as HAND
                      FROM
                      player
                      
                      ")




players <- subset(players, players[,2]>0)



for ( x in 1:17918)
{
  if(players[x,2] <= 18.5) {players[x,2] <- "U"} 
  else if(players[x,2] <= 24.9) {players[x,2] <- "H"}
  else if(players[x,2] <= 29.9) {players[x,2] <- "O"}
  else {players[x,2] <- "B"}
}

batting <-  merge(batting, players, by="player_id" )
x <- data.matrix(batting[, c('TRIPLE', 'HOME_RUNS', 'SINGLES', 'WALKS', 'DOUBLE', 'INT_WALKS', 'STOLEN_BASES', 'HIT_BY_PITCH')])

ridge_model_y_predictions <- data.frame(Prediction = 1:500, Actual= 1:500)
ridge_model_y_predictions[,1] <- predict(ridge_model, s = best_lambda_r, newx = x)
ridge_model_y_predictions[,2] <- batting$RUNS

lasso_model_y_predictions <- data.frame(Prediction = 1:500, Actual = 1:500)
lasso_model_y_predictions[,1] <- predict(cv_model, s = best_lambda, newx = x)
lasso_model_y_predictions[,2] <- batting$RUNS


stat_model_y_predictions <- data.frame(Prediction = 1:500, Actual = 1:500)
stat_model_y_predictions[,1] <- predict(stat_model, newdata = batting)
stat_model_y_predictions[,2] <- batting$RUNS

slm_y_predictions <- data.frame(Prediction = 1:500, Actual = 1:500)
slm_y_predictions[,1] <- predict(slm, newdata = batting)
slm_y_predictions[,2] <- batting$RUNS

```







```{r, fig.width=7,fig.height=2, fig.cap="A comparison of the Linear Models"}
ggplot() + 
  
  geom_point(aes(x=Prediction, y=Actual, color="SLM"), slm_y_predictions, size =0.25 )+
  geom_smooth(aes(x=Prediction, y=Actual, color="SLM"), slm_y_predictions, method = lm, fullrange =TRUE, size = 0.75)+
  
  geom_point(aes(x=Prediction, y=Actual, color="MLR"), stat_model_y_predictions,size = 0.25) + 
  geom_smooth(aes(x=Prediction, y=Actual, color="MLR"), stat_model_y_predictions, method = lm, fullrange =TRUE, size = 0.75)+
  
  geom_point(aes(x=Prediction, y=Actual, color="Ridge Model"), ridge_model_y_predictions, size =0.25)+
  geom_smooth(aes(x=Prediction, y=Actual, color="Ridge Model"), ridge_model_y_predictions, method = lm, fullrange =TRUE, size = 0.75)+
  
  geom_point(aes(x=Prediction, y=Actual, color="Lasso Model"), lasso_model_y_predictions, size =0.25 )+
  geom_smooth(aes(x=Prediction, y=Actual, color="Lasso Model"), lasso_model_y_predictions, method = lm, fullrange =TRUE, size = 0.75)+
  
  labs(color = "Model")
```

| Model Type       |                                                                                                                                                      $R^2$ |                                                                                MSE |
|:------------------------------------------|--------------:|--------------:|
| SLR              |                                 `r 1-(sum((slm_y_predictions[,1]-slm_y_predictions[,2])^2)/sum((slm_y_predictions[,2]-sum(slm_y_predictions[,2])/500)^2))` |                 `r (1/500) * sum((slm_y_predictions[,2]-slm_y_predictions[,1])^2)` |
| MLR              |     `r 1-(sum((stat_model_y_predictions[,1]-stat_model_y_predictions[,2])^2)/sum((stat_model_y_predictions[,2]-sum(stat_model_y_predictions[,2])/500)^2))` |   `r (1/500) * sum((stat_model_y_predictions[,2]-stat_model_y_predictions[,1])^2)` |
| Ridge Regression | `r 1-(sum((ridge_model_y_predictions[,1]-ridge_model_y_predictions[,2])^2)/sum((ridge_model_y_predictions[,2]-sum(ridge_model_y_predictions[,2])/500)^2))` | `r (1/500) * sum((ridge_model_y_predictions[,2]-ridge_model_y_predictions[,1])^2)` |
| Lasso Regression | `r 1-(sum((lasso_model_y_predictions[,1]-lasso_model_y_predictions[,2])^2)/sum((lasso_model_y_predictions[,2]-sum(lasso_model_y_predictions[,2])/500)^2))` | `r (1/500) * sum((lasso_model_y_predictions[,2]-lasso_model_y_predictions[,1])^2)` |

### Analysis

As some predictors had a very high level of collinearity, we elected to use shrinkage methods to fit a model to all predictors. The graph and table above were generated for several different sets of 500 new random observations from our original data set. In each case, the patterns displayed were consistent with those show above. The Lasso Regression has the lowest Mean Square Error and the Highest $R^2$ of the models--with the Ridge Regression close behind. On the other hand, the Singular linear regression has the lowest $R^2$ and MSE. The Multi-Linear Regression has a slightly lower $R^2$ and MSE than the Lasso and Ridge Regressions. However, it is very close to the shrinkage models and fits the data well--so it might be a good idea to use it if ease of explainability is important.

### Investigation - Principle Component Analysis

```{r, echo =FALSE}
batting <- dbGetQuery(ball, "
                            SELECT
                            sum(ab) AS AT_BAT,
                            player_id,
                            sum(r) AS RUNS,
                            sum(hr) AS HOME_RUNS, 
                            sum(triple) AS TRIPLE,
                            sum(double) AS DOUBLE,
                            (sum(h) -  sum(hr) - sum(triple) - sum(double)) AS SINGLES,
                            sum(bb) AS WALKS,
                            sum(ibb) AS INT_WALKS,
                            sum(sb) AS STOLEN_BASES,
                            sum(hbp) AS HIT_BY_PITCH
                            
                            FROM
                            batting
                            where
                            year > 2000
                            group by
                            player_id
                            
                   ")
sumbat <- batting
batting <- subset(batting,batting[,1]>100)

set.seed(5)
batting <- sample_n(batting, 500, replace = FALSE)

players <- dbGetQuery(ball, "
                      
                      SELECT 
                      player_id,
                      (weight / POWER(height, 2)) *703 AS BMI,
                      bats as HAND
                      FROM
                      player
                      
                      ")




players <- subset(players, players[,2]>0)



for ( x in 1:17918)
{
  if(players[x,2] <= 18.5) {players[x,2] <- "U"} 
  else if(players[x,2] <= 24.9) {players[x,2] <- "H"}
  else if(players[x,2] <= 29.9) {players[x,2] <- "O"}
  else {players[x,2] <- "B"}
}

batting <-  merge(batting, players, by="player_id" )
```

We chose Principal Components Analysis for our innovation because this method is used when there are a large number of predictors. The goal of this method is to replace our predictors with a smaller number of linear combinations of the predictors. We are essentially transforming our data into a lower-dimensional space while collating highly correlated variables together, allowing us to more easily understand and visualize our data.

```{r include =FALSE}
# Removing unnecessary columns
numerical_data <- batting[,4:11]

# Data normalization
data_normalized <- scale(numerical_data)

# PCA computation - computing our eigenvalues
data.pca <- princomp(data_normalized)
summary(data.pca) # components one and two have the highest variance

# Loading matrix
data.pca$loadings[, 1:2] # weights of component one are pretty evenly spread, while component two puts more weight on hit by pitch and triples
```

### Visualizations

```{r, fig.cap = "Component contributions to the total variance"}
# Scree plot - importance of each component//contribution to total variance
fviz_eig(data.pca, addlabels=TRUE)
```

This plot displays the eigenvalues and shows us that the first two components contribute the most the total variance.

```{r, include = FALSE}
# Biplot of the attributes - visualize similarities between samples and see impact of each attribute on components
fviz_pca_var(data.pca, col.var="black")

# Contribution of each variable - how much each variable is represented in a given component (utilizing square cosine) 
# High value means good representation
fviz_cos2(data.pca, choice="var", axes=1:2)
```

```{r fig.cap = "Biplot combined with cos2"}
# Biplot combined with cos2
fviz_pca_var(data.pca, col.var = "cos2",
            gradient.cols = c("black", "orange", "green"),
            repel = TRUE)
```

In this plot, predictors that are grouped together are correlated to each other. In our case, home runs, intentional walks, hit by pitches, walks, doubles and singles are positively correlated together in both components. Additionally, stolen bases and triples are correlated to each other positively in component one and negatively in component two. Finally, from this plot we can see that predictors that are farther from the origin and closer to green (representing a high square cosine) are better represented. For our predictors, they are all represented fairly similarly, with doubles being the most and hit by pitches and intentional walks falling behind.

# Points of interest

We noted that in both of our Ridge and Lasso regressions that the number of Triples that a player scored had the largest effect on the number of Runs that they would go on and achieve. This makes sense as getting to third base in one hit would significantly increase the odds of making it to the home base. Interestingly enough though, Doubles and Home runs both had a very similar effect--implying that training players to get good at getting to the second base will result in similar results of training them to hit home runs more consistently. 

Additionally, we would like to note that it may be worthwhile to conduct a similar experiment investigating the expected chance of achieving a run instead of the number of runs scored. Some predictors might be inflated as a player who is not particularly skilled may be given an opportunity to bat more than usual--which could affect this data. Since we only polled information from the MLB in recent years, it is our belief that this will not be the case as all players are of a high skill level.



# Summary

To best model the expected number of Runs that a player will have on record given observations of their performance, We would suggest using the Multi-Linear Regression or Lasso Regression. While a Singular linear regression with Doubles is not the worst model, it can be significantly improved on. The MLR is not as good of a fit as the Lasso Regression, but it is much easier to explain and can help players understand what to focus on if they want to increase their number of runs. On the other hand, the Lasso Regression is an incredibly well fit model that can accurately predict the expected number of runs better than any other proposed model. We believe that the Lasso Regression was so successful because we had a lot of predictors included in our data and the Lasso Regression excels when this is the case. While principle component analysis did result in some very interesting results, we found that for the purposes of this analysis it did not increase accuracy or make the model easier to comprehend for the end users.

